{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "\n",
    "# TODO: fill this in based on where you saved the training and testing data\n",
    "training_file = \"traffic-signs-data/train.p\"\n",
    "testing_file = \"traffic-signs-data/test.p\"\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_test, y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3)\n",
      "34799\n"
     ]
    }
   ],
   "source": [
    "X_train.shape\n",
    "print(X_train[0,:,:,:].shape)\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ryosuke/anaconda/envs/Udacity/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = tf.placeholder(tf.float32,[None,32,32,3])\n",
    "labels = tf.placeholder(tf.int32)\n",
    "labels_oh = tf.one_hot(labels,43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def LeNet(x):\n",
    "    conv1 = tf.layers.conv2d(x,6,2,padding=\"valid\",activation=tf.nn.relu)\n",
    "    max_pool1 = tf.layers.max_pooling2d(conv1,2,2,padding=\"valid\")\n",
    "    conv2 = tf.layers.conv2d(max_pool1,16,1,padding=\"valid\",activation=tf.nn.relu)\n",
    "    max_pool2 = tf.layers.max_pooling2d(conv2,2,2,padding =\"valid\")\n",
    "    flatten = tf.contrib.layers.flatten(max_pool2)\n",
    "    dense1 = tf.layers.dense(flatten,120,activation=tf.nn.relu)\n",
    "    dense1 = tf.nn.dropout(dense1, keep_prob)\n",
    "    dense2 = tf.layers.dense(dense1,84,activation=tf.nn.relu)\n",
    "    dense3 = tf.layers.dense(dense2,43)\n",
    "    return dense3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "logits = LeNet(features)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels_oh)\n",
    "#tf.summary.histogram(\"cross_entropy\",cross_entropy)\n",
    "loss_op= tf.reduce_mean(cross_entropy)\n",
    "#tf.summary.histogram(\"loss\",loss_op)\n",
    "train_op= tf.train.AdamOptimizer().minimize(loss_op)\n",
    "correct_prediction = tf.equal(tf.argmax(logits,1), tf.argmax(labels_oh,1))\n",
    "accuracy_op = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Train your model here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "BATCH_SIZE=64\n",
    "def eval_on_data(X,y):\n",
    "    num_examples = len(X)\n",
    "    total_acc = 0\n",
    "    total_loss = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0,num_examples,BATCH_SIZE):\n",
    "        #X,y =shuffle(X,y)\n",
    "        \n",
    "        end = offset + BATCH_SIZE\n",
    "        X_batch = X[offset:end]\n",
    "        y_batch = y[offset:end]\n",
    "        loss,acc = sess.run([loss_op,accuracy_op], feed_dict ={features:X_batch,labels:y_batch,keep_prob:1.0})\n",
    "        total_loss += (loss*len(X_batch))\n",
    "        total_acc += (acc*len(X_batch))\n",
    "    return total_loss/num_examples,total_acc/num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Time: 10.450 seconds\n",
      "Validation Loss =2.5429\n",
      "Validation Accuracy =0.2935\n",
      "\n",
      "Epoch 2\n",
      "Time: 11.096 seconds\n",
      "Validation Loss =1.8726\n",
      "Validation Accuracy =0.4364\n",
      "\n",
      "Epoch 3\n",
      "Time: 11.821 seconds\n",
      "Validation Loss =1.6464\n",
      "Validation Accuracy =0.4639\n",
      "\n",
      "Epoch 4\n",
      "Time: 10.412 seconds\n",
      "Validation Loss =1.4533\n",
      "Validation Accuracy =0.5341\n",
      "\n",
      "Epoch 5\n",
      "Time: 11.796 seconds\n",
      "Validation Loss =1.3569\n",
      "Validation Accuracy =0.5489\n",
      "\n",
      "Model saved\n",
      "Epoch 6\n",
      "Time: 10.668 seconds\n",
      "Validation Loss =1.2211\n",
      "Validation Accuracy =0.5989\n",
      "\n",
      "Epoch 7\n",
      "Time: 11.014 seconds\n",
      "Validation Loss =1.1367\n",
      "Validation Accuracy =0.6336\n",
      "\n",
      "Epoch 8\n",
      "Time: 10.246 seconds\n",
      "Validation Loss =1.0389\n",
      "Validation Accuracy =0.6608\n",
      "\n",
      "Epoch 9\n",
      "Time: 10.190 seconds\n",
      "Validation Loss =1.0024\n",
      "Validation Accuracy =0.6740\n",
      "\n",
      "Epoch 10\n",
      "Time: 10.304 seconds\n",
      "Validation Loss =0.8753\n",
      "Validation Accuracy =0.7224\n",
      "\n",
      "Model saved\n",
      "Epoch 11\n",
      "Time: 11.057 seconds\n",
      "Validation Loss =0.8356\n",
      "Validation Accuracy =0.7316\n",
      "\n",
      "Epoch 12\n",
      "Time: 10.607 seconds\n",
      "Validation Loss =0.8174\n",
      "Validation Accuracy =0.7335\n",
      "\n",
      "Epoch 13\n",
      "Time: 10.681 seconds\n",
      "Validation Loss =0.7794\n",
      "Validation Accuracy =0.7460\n",
      "\n",
      "Epoch 14\n",
      "Time: 10.216 seconds\n",
      "Validation Loss =0.7084\n",
      "Validation Accuracy =0.7635\n",
      "\n",
      "Epoch 15\n",
      "Time: 10.108 seconds\n",
      "Validation Loss =0.6574\n",
      "Validation Accuracy =0.7957\n",
      "\n",
      "Model saved\n",
      "Epoch 16\n",
      "Time: 10.591 seconds\n",
      "Validation Loss =0.6555\n",
      "Validation Accuracy =0.7825\n",
      "\n",
      "Epoch 17\n",
      "Time: 10.170 seconds\n",
      "Validation Loss =0.5841\n",
      "Validation Accuracy =0.8185\n",
      "\n",
      "Epoch 18\n",
      "Time: 10.170 seconds\n",
      "Validation Loss =0.5851\n",
      "Validation Accuracy =0.8082\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-1e3f05f58f2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moffset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_on_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Ryosuke/anaconda/envs/Udacity/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Ryosuke/anaconda/envs/Udacity/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Ryosuke/anaconda/envs/Udacity/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/Ryosuke/anaconda/envs/Udacity/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Ryosuke/anaconda/envs/Udacity/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "import time\n",
    "training_epochs=50\n",
    "batch_size=64\n",
    "val_loss_his=[]\n",
    "val_acc_his=[]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    num_examples=len(X_train)\n",
    "    for i in range(training_epochs):\n",
    "        X_train,y_train =shuffle(X_train,y_train)\n",
    "        t0 =time.time()\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            X_batch, y_batch = X_train[offset:end], y_train[offset:end]\n",
    "            sess.run(train_op, feed_dict={features: X_batch, labels: y_batch,keep_prob:0.5})\n",
    "         \n",
    "        val_loss, val_acc = eval_on_data(X_val, y_val)\n",
    "        val_loss_his.append(val_loss)\n",
    "        val_acc_his.append(val_acc)\n",
    "        print(\"Epoch\", i+1)\n",
    "        print(\"Time: %.3f seconds\" % (time.time() - t0))\n",
    "        print(\"Validation Loss =%.4f\" %(val_loss))\n",
    "        print(\"Validation Accuracy =%.4f\" %(val_acc))\n",
    "        print(\"\")\n",
    "        \n",
    "        if (i+1) % 5 ==0:\n",
    "            saver.save(sess, 'traffic_sign_keep0.5')\n",
    "            print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test my model\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "loader = tf.train.import_meta_graph('traffic_sign.meta')\n",
    "loader.restore(sess, tf.train.latest_checkpoint('./'))\n",
    "\n",
    "test_loss, test_acc = eval_on_data(X_test, y_test)\n",
    "print(\"Test Accuracy = {:.4f}\".format(test_acc))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:Udacity]",
   "language": "python",
   "name": "conda-env-Udacity-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
